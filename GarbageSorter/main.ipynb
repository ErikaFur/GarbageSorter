{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP7LnIAzec9PJ8pqTfNEleZ"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Architecture"
   ],
   "metadata": {
    "id": "qH2D0v5gEqTa",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#output - vector of vectors, labels - vactor\n",
    "def accuracy(outputs, labels):\n",
    "    return torch.tensor(torch.sum(outputs.argmax(1) == labels.argmax(1)).item() / len(labels))\n",
    "\n",
    "#implement Base for Classification\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        #print(batch.shape)\n",
    "        #print()\n",
    "        #batch - (img, label)\n",
    "        self.train()\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        #batch - (img, label)\n",
    "        self.eval() \n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        #outputs - list of dicts of validations \n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(f\"Epoch {epoch+1}: train_loss: {result['train_loss']}, val_loss: {result['val_loss']}, val_acc: {result['val_acc']}\")\n",
    "\n",
    "class ImageClassificationInception(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        #print(batch.shape)\n",
    "        #print()\n",
    "        #batch - (img, label)\n",
    "        self.train() \n",
    "        images, labels = batch \n",
    "        outputs = self(images) \n",
    "        loss1 = F.cross_entropy(outputs, labels)\n",
    "        loss = loss1\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        #batch - (img, label)\n",
    "        self.eval() \n",
    "        images, labels = batch \n",
    "        outputs = self(images) \n",
    "        loss1 = F.cross_entropy(outputs, labels)\n",
    "        loss = loss1\n",
    "        acc = accuracy(outputs, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        #outputs - list of dicts of validations \n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(f\"Epoch {epoch+1}: train_loss: {result['train_loss']}, val_loss: {result['val_loss']}, val_acc: {result['val_acc']}\")"
   ],
   "metadata": {
    "id": "F2GE7z5FElOP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "classDecode = {1:\"paper/cardboard\", 2: \"metal\", 3: \"plastic\", 4: \"glass\"}\n",
    "class ResNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.resnet50(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "class DenseNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.densenet121(pretrained=True)\n",
    "        self.network.classifier = nn.Linear(1024, len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "class InceptionNet(ImageClassificationInception):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.inception_v3(pretrained=True)\n",
    "        self.network.aux_logits=False\n",
    "        num_ftrs = self.network.AuxLogits.fc.in_features\n",
    "        self.network.AuxLogits.fc = nn.Linear(num_ftrs, len(classDecode.values()))\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs,len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "\n",
    "class VGGNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.vgg16(pretrained=True)\n",
    "        # Replace last layer\n",
    "        self.network.classifier[6] = torch.nn.Linear(4096, len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "class Net(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=(1,1))\n",
    "        self.conv2 = nn.Conv2d(16, 16, 3, padding=(1,1))\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=(1,1))\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4 , 128)\n",
    "        self.fc3 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.pool(F.relu(self.conv6(x)))\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x)\n"
   ],
   "metadata": {
    "id": "Q36t2RysEocw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model loading"
   ],
   "metadata": {
    "id": "Q5UnqbnjEuGe",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n"
   ],
   "metadata": {
    "id": "CdxTtCkAE0Pt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import time\n",
    "\n",
    "def read_and_resize(filename, grayscale = False, fx= 1, fy=1):\n",
    "    #read file\n",
    "    if grayscale:\n",
    "        img_result = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        imgbgr = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "        img_result = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2RGB)\n",
    "    img_result = cv2.resize(img_result, None, fx=fx, fy=fy, interpolation = cv2.INTER_CUBIC)\n",
    "    return img_result\n",
    "\n",
    "def getImageFromFolderAndMove(pathToImage, pathNewFolderImages):\n",
    "    #get image and move produced image to another folder\n",
    "    out = []\n",
    "    if not os.path.isdir(pathNewFolderImages):\n",
    "        os.mkdir(pathNewFolderImages)\n",
    "    if len(os.listdir(pathToImage)) == 0:\n",
    "        print(\"Folder toSort is empty!\")\n",
    "    for filename in os.listdir(pathToImage):\n",
    "        imgPath = (pathToImage+\"/\").replace(\"//\", \"/\")+filename\n",
    "        out = read_and_resize(imgPath)\n",
    "        shutil.move(imgPath, (pathNewFolderImages+\"/\").replace(\"//\", \"/\")+filename)\n",
    "        return [out, filename]\n",
    "\n",
    "def resizeImage(img, size):\n",
    "    #reshape to the shape of (size, size)\n",
    "    return cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA).astype(\"float32\")/255\n",
    "\n",
    "def convertImg(img, device):\n",
    "    #prepare image to pass it to the model\n",
    "    return torch.tensor([img.swapaxes(2,1).swapaxes(1,0)]).to(device)\n",
    "\n",
    "def passToModel(model, image):\n",
    "    return model(image).argmax(1)\n",
    "\n",
    "def loadModel(pathTo, device):\n",
    "    model = to_device(DenseNet(), device)\n",
    "    model.load_state_dict(torch.load(pathTo, map_location=device))\n",
    "    return model\n",
    "\n",
    "def logInfo(pathToCsv, imgName, predict, predictClass):\n",
    "    if not os.path.isfile(pathToCsv): \n",
    "        df = pd.DataFrame({'name': [],\n",
    "                   'class': [],\n",
    "                   'classname': []})\n",
    "    else:\n",
    "        df = pd.read_csv(pathToCsv)\n",
    "    new_row = pd.DataFrame({'name': [imgName],\n",
    "                   'class': [predict],\n",
    "                   'classname': [predictClass]})\n",
    "    df = df.append(new_row, ignore_index=True)\n",
    "    df.to_csv(pathToCsv, index=False)\n",
    "\n",
    "\n",
    "def getResizePass(pathToModel, pathToImage, pathNewFolderImages, csvFilePath, classDecode):\n",
    "    device = get_default_device()\n",
    "    model = loadModel(pathToModel, device)\n",
    "    model.eval()\n",
    "    img, filename = getImageFromFolderAndMove(pathToImage, pathNewFolderImages)\n",
    "    resImg = convertImg(resizeImage(img, 256), device)\n",
    "\n",
    "    out = passToModel(model, resImg)\n",
    "    cls = classDecode[int(out[0]+1)]\n",
    "    numCls = int(out[0]+1)\n",
    "    log = logInfo(csvFilePath, filename, numCls, cls)\n",
    "    print(f\"Model predicted class {numCls}, which is a {cls}\")\n",
    "    \n",
    "def main():\n",
    "    localPath = \"./processing/\"\n",
    "    path = localPath\n",
    "    pathToModel = path + \"model/denseNetModel.pt\"  # pretrained model. It takes RGB images with size 256x256\n",
    "    imgPath = path + \"toSort\"  # folder with all images to sort\n",
    "    imgNewPath = path + \"sorted\"  # folder with all sorted images\n",
    "    csvPath = path + \"logGarbage.csv\"  # file for the logging\n",
    "    classDecoder = {1: \"paper/cardboard\", 2: \"metal\", 3: \"plastic\", 4: \"glass\"}  # all classes\n",
    "\n",
    "    start = time.time()\n",
    "    getResizePass(pathToModel, imgPath, imgNewPath, csvPath, classDecoder)\n",
    "    end = time.time()\n",
    "    print(f\"Time of execution is {end - start} seconds!\")"
   ],
   "metadata": {
    "id": "4W4E1qXtFk7D",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Place your image in folder GarbageSorter/processing/toSort\n",
    "2. Cell with main() can be run multiple times unil folder toSort is not empty\n",
    "3. Predicted class will appear in the console as prediction will be over.\n",
    "4. Logs appear in GarbageSorter/processing/logGarbage.csv after each prediction. Each record contains: name of processed image, class number and class name\n",
    "5. All processed images moved from folder GarbageSorter/processing/toSort in the folder GarbageSorter/processing/sorted\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "jkmmi6sZEQgS",
    "outputId": "15c57fdb-c872-4271-e16b-f280dd780ed5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted class 1, which is a paper/cardboard\n",
      "Time of execution is 0.829758882522583 seconds!\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}