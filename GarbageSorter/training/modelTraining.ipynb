{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ILi8A2iKP1GS"
   },
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.convolutional import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from torchvision.transforms import transforms\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collab code!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall --no-deps kaggle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle datasets download -d mostafaabla/garbage-classification -p /content/sample_data/ --unzip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data processing\n",
    "def read_and_resize(filename, grayscale = False, fx= 1, fy=1):\n",
    "    if grayscale:\n",
    "        img_result = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        imgbgr = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "        img_result = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2RGB)\n",
    "    img_result = cv2.resize(img_result, None, fx=fx, fy=fy, interpolation = cv2.INTER_CUBIC)\n",
    "    return img_result\n",
    "\n",
    "#show images\n",
    "def show_in_row(list_of_images, titles = None, disable_ticks = False):\n",
    "    count = len(list_of_images)\n",
    "    for idx in range(count):\n",
    "        subplot = plt.subplot(1, count, idx+1)\n",
    "        if titles is not None:\n",
    "            subplot.set_title(titles[idx])\n",
    "\n",
    "        img = list_of_images[idx]\n",
    "        cmap = 'gray' if (len(img.shape) == 2 or img.shape[2] == 1) else None\n",
    "        subplot.imshow(img, cmap=cmap)\n",
    "        if disable_ticks:\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "#open txt file using path to the file and file_name.txt\n",
    "def openWithTxt(txt: str, path:str):\n",
    "    outData = []\n",
    "    with open(\"/content/sample_data/\"+txt) as f:\n",
    "        for i in f.readlines():\n",
    "            img ,classNum = i.split()\n",
    "            classNum = int(classNum)\n",
    "            img = read_and_resize(path+f\"{deIdx[classNum]}/\"+img).astype(\"float32\")/255\n",
    "            s = img.shape\n",
    "            img = cv2.resize(img, (s[0],s[0]), interpolation = cv2.INTER_AREA)\n",
    "            #outData.extend(rotate2sides(img, classNum))\n",
    "            outData.append((img, classNum))\n",
    "    return np.array(outData)\n",
    "\n",
    "def openWith(dfX, dfY):\n",
    "    outData = []\n",
    "    for i in range(len(dfX)):\n",
    "        path = \"./sample_data/garbageAll/\"\n",
    "        img = dfX[i]\n",
    "        classNum = dfY[i]\n",
    "        img = read_and_resize(path+img).astype(\"float32\")/255\n",
    "        img = cv2.resize(img, (300,300), interpolation = cv2.INTER_AREA)\n",
    "        outData.append((img, classNum))\n",
    "    return np.array(outData)\n",
    "\n",
    "# takes image ans its classNumber, and produce 4 rotaded images on exact degree (0, 90, 180, 270)\n",
    "def rotate4sides(img, classNum):\n",
    "    outData = []\n",
    "    outData.append(np.array([img, classNum]))\n",
    "    outData.append(np.array([cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE), classNum]))\n",
    "    outData.append(np.array([cv2.rotate(img, cv2.ROTATE_180), classNum]))\n",
    "    outData.append(np.array([cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE), classNum]))\n",
    "    return outData\n",
    "\n",
    "def rotate2sides(img, classNum):\n",
    "    outData = []\n",
    "    outData.append(np.array([img, classNum]))\n",
    "    outData.append(np.array([cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE), classNum]))\n",
    "    return outData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def moveToAll(neededDirs):\n",
    "    pathTo   = \"./sample_data/garbageAll/\"\n",
    "    pathFrom = \"./sample_data/garbage_classification/\"\n",
    "\n",
    "    if not os.path.isdir(pathTo):\n",
    "        os.mkdir(pathTo)\n",
    "    else:\n",
    "        shutil.rmtree(pathTo)\n",
    "        os.mkdir(pathTo)\n",
    "\n",
    "    for folder in neededDirs:\n",
    "        print(len(os.listdir(pathFrom+folder)))\n",
    "        for filename in os.listdir(pathFrom+folder):\n",
    "            shutil.copy2(pathFrom+folder+\"/\"+filename, pathTo)\n",
    "\n",
    "neededDirs = [\"brown-glass\", \"cardboard\", \"green-glass\", \"plastic\", \"paper\", \"white-glass\", \"metal\"]\n",
    "moveToAll(neededDirs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#upload .csv in a folder\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/preprocessed_data.csv\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "classDecode = {1:\"paper/cardboard\", 2: \"metal\", 3: \"plastic\", 4: \"glass\"}\n",
    "\n",
    "x, x_test, y, y_test = train_test_split(df[\"photo\"],df[\"class\"],test_size=0.2,train_size=0.8)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x,y,test_size = 0.20,train_size =0.80)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "x_train.reset_index(inplace=True, drop=True)\n",
    "x_cv.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_cv.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testData = openWith(x_test, y_test)\n",
    "xTest = np.stack(testData[:,0])\n",
    "yTest =  to_categorical(testData[:,1],num_classes = len(classDecode.values())+1)[:,1:]\n",
    "testData.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainData = openWith(x_train, y_train)\n",
    "xTrain = np.stack(trainData[:,0])\n",
    "yTrain = to_categorical(trainData[:,1],num_classes = len(classDecode.values())+1)[:,1:]\n",
    "trainData.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valData = openWith(x_cv, y_cv)\n",
    "xVal = np.stack(valData[:,0])\n",
    "yVal = to_categorical(valData[:,1],num_classes = len(classDecode.values())+1)[:,1:]\n",
    "valData.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yTrain.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(x_test)):\n",
    "    path = \"./sample_data/garbageAll/\"\n",
    "    img = x_test[i]\n",
    "    img = read_and_resize(path+img).astype(\"float32\")/255\n",
    "    img = cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA)\n",
    "    show_in_row([img])\n",
    "    break\n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_in_row(xTest[:5], yTest[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#output - vector of vectors, labels - vactor\n",
    "def accuracy(outputs, labels):\n",
    "    return torch.tensor(torch.sum(outputs.argmax(1) == labels.argmax(1)).item() / len(labels))\n",
    "\n",
    "#implement Base for Classification\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        #print(batch.shape)\n",
    "        #print()\n",
    "        #batch - (img, label)\n",
    "        self.train() \n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        #batch - (img, label)\n",
    "        self.eval() \n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        #outputs - list of dicts of validations \n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(f\"Epoch {epoch+1}: train_loss: {result['train_loss']}, val_loss: {result['val_loss']}, val_acc: {result['val_acc']}\")\n",
    "\n",
    "class ImageClassificationInception(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        #print(batch.shape)\n",
    "        #print()\n",
    "        #batch - (img, label)\n",
    "        self.train() \n",
    "        images, labels = batch \n",
    "        outputs = self(images) \n",
    "        loss1 = F.cross_entropy(outputs, labels)\n",
    "        loss = loss1\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        #batch - (img, label)\n",
    "        self.eval() \n",
    "        images, labels = batch \n",
    "        outputs = self(images) \n",
    "        loss1 = F.cross_entropy(outputs, labels)\n",
    "        loss = loss1\n",
    "        acc = accuracy(outputs, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        #outputs - list of dicts of validations \n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(f\"Epoch {epoch+1}: train_loss: {result['train_loss']}, val_loss: {result['val_loss']}, val_acc: {result['val_acc']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class ResNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.resnet50(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "class DenseNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.densenet121(pretrained=True)\n",
    "        self.network.classifier = nn.Linear(1024, len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "class InceptionNet(ImageClassificationInception):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.inception_v3(pretrained=True)\n",
    "        self.network.aux_logits=False\n",
    "        num_ftrs = self.network.AuxLogits.fc.in_features\n",
    "        self.network.AuxLogits.fc = nn.Linear(num_ftrs, len(classDecode.values()))\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs,len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "\n",
    "class VGGNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.vgg16(pretrained=True)\n",
    "        # Replace last layer\n",
    "        self.network.classifier[6] = torch.nn.Linear(4096, len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "class Net(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=(1,1))\n",
    "        self.conv2 = nn.Conv2d(16, 16, 3, padding=(1,1))\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=(1,1))\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4 , 128)\n",
    "        self.fc3 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.pool(F.relu(self.conv6(x)))\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, x, device, len):\n",
    "        self.dl = x\n",
    "        self.device = device\n",
    "        self.len = len\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for item in self.dl: \n",
    "            yield to_device(item, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.len = len(x)\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, item):\n",
    "        #print(type(self.x[item]))\n",
    "        return self.transform(self.x[item]), torch.from_numpy(self.y[item])\n",
    "\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "batch_size = 32\n",
    "\n",
    "print(xTrain.shape)\n",
    "print(yTrain.shape)\n",
    "\n",
    "\n",
    "myDataTrain = MyData(xTrain,yTrain, transform)\n",
    "myDataVal = MyData(xVal,yVal, transform)\n",
    "myDataTest = MyData(xTest,yTest, transform)\n",
    "\n",
    "dataTrain = torch.utils.data.DataLoader(myDataTrain, batch_size=batch_size)\n",
    "dataVal = torch.utils.data.DataLoader(myDataVal, batch_size=batch_size)\n",
    "dataTest = torch.utils.data.DataLoader(myDataTest, batch_size=batch_size)\n",
    "\n",
    "dataTrain = DeviceDataLoader(dataTrain, device,len(yTrain))\n",
    "dataVal = DeviceDataLoader(dataVal, device,len(yVal))\n",
    "dataTest = DeviceDataLoader(dataTest, device,len(yTest))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inception"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "Ng4SWkUgCTjg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0.00/104M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df9de60ad39f4255a596f2795c6ce779"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 1.391257882118225, 'val_acc': 0.22752192616462708}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "model = to_device(InceptionNet(), device)\n",
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "M0yVLJwlCTjh",
    "outputId": "f54b2850-fc06-4c25-d48a-05298164919c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191,
     "referenced_widgets": [
      "df9de60ad39f4255a596f2795c6ce779",
      "4b9ef7b515c34d179cbdcb4e5d257e1a",
      "27b23169b855496992691357baef2be3",
      "b7465566f64b45398d246d557662c508",
      "f6dee2c4aca1421ba9e463cbff32410d",
      "d8ad90a9ad5b48fbac09415b8dc12078",
      "1908f939f85a44b397869894818ee7d0",
      "afe773d0fa064ee6b7ca1139d6129cb2",
      "876fa66e69534de0b9d99fa8abd75900",
      "1ff642c3c2ec4ea6a922a66eedde7ef8",
      "c45cdc3876ed42e8a4cd97a1cae2b5d6"
     ]
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1: train_loss: 1.084760308265686, val_loss: 0.9013890027999878, val_acc: 0.8895833492279053\n",
      "Epoch 2: train_loss: 0.8326805830001831, val_loss: 0.8320066928863525, val_acc: 0.9270833134651184\n",
      "Epoch 3: train_loss: 0.7704275250434875, val_loss: 0.81536865234375, val_acc: 0.9375\n",
      "Epoch 4: train_loss: 0.7563201785087585, val_loss: 0.8115494847297668, val_acc: 0.9354166388511658\n",
      "Epoch 5: train_loss: 0.7518216371536255, val_loss: 0.8067586421966553, val_acc: 0.9437500238418579\n",
      "Epoch 6: train_loss: 0.7498541474342346, val_loss: 0.804380476474762, val_acc: 0.9458333253860474\n",
      "Epoch 7: train_loss: 0.7488043308258057, val_loss: 0.8027440905570984, val_acc: 0.9479166865348816\n",
      "Epoch 8: train_loss: 0.7478309273719788, val_loss: 0.8029911518096924, val_acc: 0.9437500238418579\n",
      "Epoch 9: train_loss: 0.7472827434539795, val_loss: 0.8019663095474243, val_acc: 0.9437500238418579\n",
      "Epoch 10: train_loss: 0.746649444103241, val_loss: 0.801336944103241, val_acc: 0.9458333253860474\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5\n",
    "\n",
    "history = fit(num_epochs, lr, model, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "CpdDIknwCTjh",
    "outputId": "ddf21e39-962a-4715-9102-4371e8d4267b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 0.7987716197967529, 'val_acc': 0.9506579041481018}"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "pkBdWopPCTjh",
    "outputId": "209d4746-a0f6-4de7-a511-f82d83ed87b6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DenseNet\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "7sB13Y4nCTjh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 1.3936597108840942, 'val_acc': 0.27892857789993286}"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model = to_device(DenseNet(), device)\n",
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3g6aPtubCTjh",
    "outputId": "bfa27ac8-e730-4614-9f1e-a85b4c9c18bc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1: train_loss: 1.0039222240447998, val_loss: 0.8223397731781006, val_acc: 0.9473958611488342\n",
      "Epoch 2: train_loss: 0.809501051902771, val_loss: 0.7925328016281128, val_acc: 0.9709821343421936\n",
      "Epoch 3: train_loss: 0.7696688771247864, val_loss: 0.7835747003555298, val_acc: 0.9753720164299011\n",
      "Epoch 4: train_loss: 0.7567718625068665, val_loss: 0.7789515256881714, val_acc: 0.9743303656578064\n",
      "Epoch 5: train_loss: 0.7522176504135132, val_loss: 0.7769203782081604, val_acc: 0.9720238447189331\n",
      "Epoch 6: train_loss: 0.7501698136329651, val_loss: 0.7756205797195435, val_acc: 0.9743303656578064\n",
      "Epoch 7: train_loss: 0.7492964863777161, val_loss: 0.7755568623542786, val_acc: 0.9743303656578064\n",
      "Epoch 8: train_loss: 0.7483378052711487, val_loss: 0.7737051248550415, val_acc: 0.9754464030265808\n",
      "Epoch 9: train_loss: 0.7486756443977356, val_loss: 0.7779036164283752, val_acc: 0.9709077477455139\n",
      "Epoch 10: train_loss: 0.7478559017181396, val_loss: 0.7738081216812134, val_acc: 0.9720982313156128\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "L6jfba44CTji",
    "outputId": "8310f8de-8561-4bec-b814-6cbc1914e76c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 0.7829263806343079, 'val_acc': 0.9641072154045105}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "4UFoafM5CTji",
    "outputId": "194cd468-407d-4dec-bfd6-472cea558f47",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "wxIL19qXCTji"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 1.376761794090271, 'val_acc': 0.270892858505249}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "model = to_device(ResNet(), device)\n",
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ftZHzIIVCTji",
    "outputId": "98111c6a-913f-43ce-b6ac-ada8e759d7bb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1: train_loss: 0.9179803133010864, val_loss: 0.8061242699623108, val_acc: 0.9452381134033203\n",
      "Epoch 2: train_loss: 0.7851420640945435, val_loss: 0.7957051992416382, val_acc: 0.9520089030265808\n",
      "Epoch 3: train_loss: 0.7676023840904236, val_loss: 0.8021842837333679, val_acc: 0.9441964030265808\n",
      "Epoch 4: train_loss: 0.7582570910453796, val_loss: 0.8022564649581909, val_acc: 0.9453125\n",
      "Epoch 5: train_loss: 0.7551750540733337, val_loss: 0.7943219542503357, val_acc: 0.9520089030265808\n",
      "Epoch 6: train_loss: 0.7517693042755127, val_loss: 0.7813934683799744, val_acc: 0.9642857313156128\n",
      "Epoch 7: train_loss: 0.7506827116012573, val_loss: 0.7836911678314209, val_acc: 0.9587053656578064\n",
      "Epoch 8: train_loss: 0.7502644658088684, val_loss: 0.7870519757270813, val_acc: 0.9553571343421936\n",
      "Epoch 9: train_loss: 0.7497107982635498, val_loss: 0.7854815721511841, val_acc: 0.9587053656578064\n",
      "Epoch 10: train_loss: 0.7484532594680786, val_loss: 0.7848876714706421, val_acc: 0.9598214030265808\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "2eSYVzDuCTji",
    "outputId": "df72d957-16b1-4458-99f6-95aec82ac13a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 0.7842323780059814, 'val_acc': 0.9589285850524902}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "oBI3UebaCTji",
    "outputId": "cf511f3f-5d2c-4417-dabc-cb23742ea222",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG\n"
   ],
   "metadata": {
    "id": "AJSiNYB7fZwX",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model3 = to_device(VGGNet(), device)\n",
    "evaluate(model3, dataTest)"
   ],
   "metadata": {
    "id": "23aoKetOeqii",
    "outputId": "74e96d94-2321-463a-b297-13ddaa513efe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 1.3746545314788818, 'val_acc': 0.3095238208770752}"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 15\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model3, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "id": "-vYcwNOyfKlT",
    "outputId": "80a024ee-c976-4974-d4e5-f26792c94ec4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.9677273631095886, val_loss: 0.8717265725135803, val_acc: 0.8646577596664429\n",
      "Epoch 2: train_loss: 0.84929358959198, val_loss: 0.8476076722145081, val_acc: 0.8925595283508301\n",
      "Epoch 3: train_loss: 0.8223062753677368, val_loss: 0.8415981531143188, val_acc: 0.8982142806053162\n",
      "Epoch 4: train_loss: 0.8051403760910034, val_loss: 0.856124222278595, val_acc: 0.888244092464447\n",
      "Epoch 5: train_loss: 0.7976633906364441, val_loss: 0.8913146257400513, val_acc: 0.8511160612106323\n",
      "Epoch 6: train_loss: 0.7992236614227295, val_loss: 0.8433651328086853, val_acc: 0.896056592464447\n",
      "Epoch 7: train_loss: 0.7842244505882263, val_loss: 0.7988829016685486, val_acc: 0.9418154954910278\n",
      "Epoch 8: train_loss: 0.7712522745132446, val_loss: 0.8109492063522339, val_acc: 0.9317708611488342\n",
      "Epoch 9: train_loss: 0.7673804759979248, val_loss: 0.8073222041130066, val_acc: 0.9340029954910278\n",
      "Epoch 10: train_loss: 0.7665198445320129, val_loss: 0.8047615885734558, val_acc: 0.9407738447189331\n",
      "Epoch 11: train_loss: 0.7699206471443176, val_loss: 0.8085108399391174, val_acc: 0.9340773820877075\n",
      "Epoch 12: train_loss: 0.7734049558639526, val_loss: 0.826531171798706, val_acc: 0.9183779954910278\n",
      "Epoch 13: train_loss: 0.7839992046356201, val_loss: 0.8313900232315063, val_acc: 0.909375011920929\n",
      "Epoch 14: train_loss: 0.7744327187538147, val_loss: 0.8241991400718689, val_acc: 0.9160714149475098\n",
      "Epoch 15: train_loss: 0.7627151608467102, val_loss: 0.8333675861358643, val_acc: 0.9104910492897034\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "evaluate(model3, dataTest)"
   ],
   "metadata": {
    "id": "MoV-4KAYfYzv",
    "outputId": "e08bc181-449a-4c37-dced-e583160d55b4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.8236653208732605, 'val_acc': 0.917738139629364}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MyLittleModel"
   ],
   "metadata": {
    "id": "X9e6HA05ff2D",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model2 = to_device(Net(), device)\n",
    "evaluate(model2, dataTest)"
   ],
   "metadata": {
    "id": "eGeVLq-0fOcs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1: train_loss: 1.5985661745071411, val_loss: 1.59907865524292, val_acc: 0.43465909361839294\n",
      "Epoch 2: train_loss: 1.5879095792770386, val_loss: 1.5929450988769531, val_acc: 0.4517045319080353\n",
      "Epoch 3: train_loss: 1.582120656967163, val_loss: 1.5874441862106323, val_acc: 0.4545454680919647\n",
      "Epoch 4: train_loss: 1.576361060142517, val_loss: 1.5819647312164307, val_acc: 0.4630681872367859\n",
      "Epoch 5: train_loss: 1.5712506771087646, val_loss: 1.5773649215698242, val_acc: 0.47159090638160706\n",
      "Epoch 6: train_loss: 1.5662802457809448, val_loss: 1.5726343393325806, val_acc: 0.47159090638160706\n",
      "Epoch 7: train_loss: 1.560564398765564, val_loss: 1.5653364658355713, val_acc: 0.4857954680919647\n",
      "Epoch 8: train_loss: 1.553512454032898, val_loss: 1.569851279258728, val_acc: 0.4943181872367859\n",
      "Epoch 9: train_loss: 1.546003818511963, val_loss: 1.5616538524627686, val_acc: 0.5056818127632141\n",
      "Epoch 10: train_loss: 1.5410611629486084, val_loss: 1.5586732625961304, val_acc: 0.5\n",
      "Epoch 11: train_loss: 1.5371712446212769, val_loss: 1.5553393363952637, val_acc: 0.5\n",
      "Epoch 12: train_loss: 1.5330556631088257, val_loss: 1.554300308227539, val_acc: 0.4943181872367859\n",
      "Epoch 13: train_loss: 1.5291756391525269, val_loss: 1.5538989305496216, val_acc: 0.4943181872367859\n",
      "Epoch 14: train_loss: 1.5256857872009277, val_loss: 1.551945447921753, val_acc: 0.5\n",
      "Epoch 15: train_loss: 1.5225411653518677, val_loss: 1.5473952293395996, val_acc: 0.5170454382896423\n",
      "Epoch 16: train_loss: 1.5202383995056152, val_loss: 1.5421479940414429, val_acc: 0.5142045617103577\n",
      "Epoch 17: train_loss: 1.5176920890808105, val_loss: 1.5363012552261353, val_acc: 0.5227272510528564\n",
      "Epoch 18: train_loss: 1.514556646347046, val_loss: 1.52908194065094, val_acc: 0.5369318127632141\n",
      "Epoch 19: train_loss: 1.512723445892334, val_loss: 1.5255613327026367, val_acc: 0.5454545617103577\n",
      "Epoch 20: train_loss: 1.5110138654708862, val_loss: 1.525581955909729, val_acc: 0.5340909361839294\n",
      "Epoch 21: train_loss: 1.5082021951675415, val_loss: 1.5250365734100342, val_acc: 0.5340909361839294\n",
      "Epoch 22: train_loss: 1.5094692707061768, val_loss: 1.525234580039978, val_acc: 0.53125\n",
      "Epoch 23: train_loss: 1.5095232725143433, val_loss: 1.5259275436401367, val_acc: 0.5340909361839294\n",
      "Epoch 24: train_loss: 1.5103774070739746, val_loss: 1.5282336473464966, val_acc: 0.5198863744735718\n",
      "Epoch 25: train_loss: 1.506618857383728, val_loss: 1.5264320373535156, val_acc: 0.5227272510528564\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model2, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cl91c3z2P1Gg",
    "outputId": "0a64519c-3c18-42e7-fc9b-a80bbb32ff5c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "evaluate(model2, dataTest)"
   ],
   "metadata": {
    "id": "ht3MrSkcRLh-",
    "outputId": "476fd114-baad-4e02-9c00-6fbfc1182cab",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 1.5115759372711182, 'val_acc': 0.524404764175415}"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "EI7eGhdeP1Gf"
   ]
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "df9de60ad39f4255a596f2795c6ce779": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b9ef7b515c34d179cbdcb4e5d257e1a",
       "IPY_MODEL_27b23169b855496992691357baef2be3",
       "IPY_MODEL_b7465566f64b45398d246d557662c508"
      ],
      "layout": "IPY_MODEL_f6dee2c4aca1421ba9e463cbff32410d"
     }
    },
    "4b9ef7b515c34d179cbdcb4e5d257e1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8ad90a9ad5b48fbac09415b8dc12078",
      "placeholder": "​",
      "style": "IPY_MODEL_1908f939f85a44b397869894818ee7d0",
      "value": "100%"
     }
    },
    "27b23169b855496992691357baef2be3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_afe773d0fa064ee6b7ca1139d6129cb2",
      "max": 108949747,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_876fa66e69534de0b9d99fa8abd75900",
      "value": 108949747
     }
    },
    "b7465566f64b45398d246d557662c508": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ff642c3c2ec4ea6a922a66eedde7ef8",
      "placeholder": "​",
      "style": "IPY_MODEL_c45cdc3876ed42e8a4cd97a1cae2b5d6",
      "value": " 104M/104M [00:00&lt;00:00, 198MB/s]"
     }
    },
    "f6dee2c4aca1421ba9e463cbff32410d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8ad90a9ad5b48fbac09415b8dc12078": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1908f939f85a44b397869894818ee7d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afe773d0fa064ee6b7ca1139d6129cb2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "876fa66e69534de0b9d99fa8abd75900": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ff642c3c2ec4ea6a922a66eedde7ef8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c45cdc3876ed42e8a4cd97a1cae2b5d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}