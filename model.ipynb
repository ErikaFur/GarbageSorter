{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ILi8A2iKP1GS"
   },
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.layers.convolutional import *\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from torchvision.transforms import transforms\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collab code!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall --no-deps kaggle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle datasets list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle datasets download -d mostafaabla/garbage-classification -p /content/sample_data/ --unzip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data processing\n",
    "def read_and_resize(filename, grayscale = False, fx= 1, fy=1):\n",
    "    if grayscale:\n",
    "        img_result = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        imgbgr = cv2.imread(filename, cv2.IMREAD_COLOR)\n",
    "        img_result = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2RGB)\n",
    "    img_result = cv2.resize(img_result, None, fx=fx, fy=fy, interpolation = cv2.INTER_CUBIC)\n",
    "    return img_result\n",
    "\n",
    "#show images\n",
    "def show_in_row(list_of_images, titles = None, disable_ticks = False):\n",
    "    count = len(list_of_images)\n",
    "    for idx in range(count):\n",
    "        subplot = plt.subplot(1, count, idx+1)\n",
    "        if titles is not None:\n",
    "            subplot.set_title(titles[idx])\n",
    "\n",
    "        img = list_of_images[idx]\n",
    "        cmap = 'gray' if (len(img.shape) == 2 or img.shape[2] == 1) else None\n",
    "        subplot.imshow(img, cmap=cmap)\n",
    "        if disable_ticks:\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "\n",
    "#open txt file using path to the file and file_name.txt\n",
    "def openWithTxt(txt: str, path:str):\n",
    "    outData = []\n",
    "    with open(\"/content/sample_data/\"+txt) as f:\n",
    "        for i in f.readlines():\n",
    "            img ,classNum = i.split()\n",
    "            classNum = int(classNum)\n",
    "            img = read_and_resize(path+f\"{deIdx[classNum]}/\"+img).astype(\"float32\")/255\n",
    "            s = img.shape\n",
    "            img = cv2.resize(img, (s[0],s[0]), interpolation = cv2.INTER_AREA)\n",
    "            #outData.extend(rotate2sides(img, classNum))\n",
    "            outData.append((img, classNum))\n",
    "    return np.array(outData)\n",
    "\n",
    "def openWith(dfX, dfY):\n",
    "    outData = []\n",
    "    for i in range(len(dfX)):\n",
    "        path = \"./sample_data/garbageAll/\"\n",
    "        img = dfX[i]\n",
    "        classNum = dfY[i]\n",
    "        img = read_and_resize(path+img).astype(\"float32\")/255\n",
    "        img = cv2.resize(img, (200,200), interpolation = cv2.INTER_AREA)\n",
    "        outData.append((img, classNum))\n",
    "    return np.array(outData)\n",
    "\n",
    "# takes image ans its classNumber, and produce 4 rotaded images on exact degree (0, 90, 180, 270)\n",
    "def rotate4sides(img, classNum):\n",
    "    outData = []\n",
    "    outData.append(np.array([img, classNum]))\n",
    "    outData.append(np.array([cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE), classNum]))\n",
    "    outData.append(np.array([cv2.rotate(img, cv2.ROTATE_180), classNum]))\n",
    "    outData.append(np.array([cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE), classNum]))\n",
    "    return outData\n",
    "\n",
    "def rotate2sides(img, classNum):\n",
    "    outData = []\n",
    "    outData.append(np.array([img, classNum]))\n",
    "    outData.append(np.array([cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE), classNum]))\n",
    "    return outData"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def moveToAll(neededDirs):\n",
    "    pathTo   = \"./sample_data/garbageAll/\"\n",
    "    pathFrom = \"./sample_data/garbage_classification/\"\n",
    "\n",
    "    if not os.path.isdir(pathTo):\n",
    "        os.mkdir(pathTo)\n",
    "    else:\n",
    "        shutil.rmtree(pathTo)\n",
    "        os.mkdir(pathTo)\n",
    "\n",
    "    for folder in neededDirs:\n",
    "        print(len(os.listdir(pathFrom+folder)))\n",
    "        for filename in os.listdir(pathFrom+folder):\n",
    "            shutil.copy2(pathFrom+folder+\"/\"+filename, pathTo)\n",
    "\n",
    "neededDirs = [\"brown-glass\", \"cardboard\", \"green-glass\", \"plastic\", \"paper\", \"white-glass\", \"metal\"]\n",
    "moveToAll(neededDirs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#upload .csv in a folder\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files.upload()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"preprocessed_data.csv\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "classDecode = {1:\"paper/cardboard\", 2: \"metal\", 3: \"plastic\", 4: \"glass\"}\n",
    "\n",
    "x, x_test, y, y_test = train_test_split(df[\"photo\"],df[\"class\"],test_size=0.2,train_size=0.8)\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(x,y,test_size = 0.20,train_size =0.80)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)\n",
    "x_train.reset_index(inplace=True, drop=True)\n",
    "x_cv.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_cv.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testData = openWith(x_test, y_test)\n",
    "xTest = np.stack(testData[:,0])\n",
    "yTest =  to_categorical(testData[:,1],num_classes = len(classDecode.values())+1)[:,1:]\n",
    "testData.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainData = openWith(x_train, y_train)\n",
    "xTrain = np.stack(trainData[:,0])\n",
    "yTrain = to_categorical(trainData[:,1],num_classes = len(classDecode.values())+1)[:,1:]\n",
    "trainData.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valData = openWith(x_cv, y_cv)\n",
    "xVal = np.stack(valData[:,0])\n",
    "yVal = to_categorical(valData[:,1],num_classes = len(classDecode.values())+1)[:,1:]\n",
    "valData.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "yTrain.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(x_test)):\n",
    "    path = \"./sample_data/garbageAll/\"\n",
    "    img = x_test[i]\n",
    "    img = read_and_resize(path+img).astype(\"float32\")/255\n",
    "    img = cv2.resize(img, (256,256), interpolation = cv2.INTER_AREA)\n",
    "    show_in_row([img])\n",
    "    break\n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_in_row(xTest[:5], yTest[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 1\n",
    "\n",
    "##  CNN (keras)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#output - vector of vectors, labels - vactor\n",
    "def accuracy(outputs, labels):\n",
    "    return torch.tensor(torch.sum(outputs.argmax(1) == labels.argmax(1)).item() / len(labels))\n",
    "\n",
    "#implement Base for Classification\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        #print(batch.shape)\n",
    "        #print()\n",
    "        #batch - (img, label)\n",
    "        self.train() \n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        #batch - (img, label)\n",
    "        self.eval() \n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        #outputs - list of dicts of validations \n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(f\"Epoch {epoch+1}: train_loss: {result['train_loss']}, val_loss: {result['val_loss']}, val_acc: {result['val_acc']}\")\n",
    "\n",
    "class ImageClassificationInception(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        #print(batch.shape)\n",
    "        #print()\n",
    "        #batch - (img, label)\n",
    "        self.train() \n",
    "        images, labels = batch \n",
    "        outputs = self(images) \n",
    "        loss1 = F.cross_entropy(outputs, labels)\n",
    "        loss = loss1\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        #batch - (img, label)\n",
    "        self.eval() \n",
    "        images, labels = batch \n",
    "        outputs = self(images) \n",
    "        loss1 = F.cross_entropy(outputs, labels)\n",
    "        loss = loss1\n",
    "        acc = accuracy(outputs, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        #outputs - list of dicts of validations \n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(f\"Epoch {epoch+1}: train_loss: {result['train_loss']}, val_loss: {result['val_loss']}, val_acc: {result['val_acc']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class ResNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.resnet50(pretrained=True)\n",
    "        # Replace last layer\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs, len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "class DenseNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.densenet121(pretrained=True)\n",
    "        self.network.classifier = nn.Linear(1024, len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "class InceptionNet(ImageClassificationInception):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = models.inception_v3(pretrained=True)\n",
    "        self.network.aux_logits=False\n",
    "        num_ftrs = self.network.AuxLogits.fc.in_features\n",
    "        self.network.AuxLogits.fc = nn.Linear(num_ftrs, len(classDecode.values()))\n",
    "        num_ftrs = self.network.fc.in_features\n",
    "        self.network.fc = nn.Linear(num_ftrs,len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "\n",
    "class VGGNet(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pretrained model\n",
    "        self.network = models.vgg16(pretrained=True)\n",
    "        # Replace last layer\n",
    "        self.network.classifier[6] = torch.nn.Linear(4096, len(classDecode.values()))\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        o = self.network(xb)\n",
    "        return F.softmax(o)\n",
    "\n",
    "class Net(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=(1,1))\n",
    "        self.conv2 = nn.Conv2d(16, 16, 3, padding=(1,1))\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, padding=(1,1))\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(64, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4 , 128)\n",
    "        self.fc3 = nn.Linear(128, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.pool(F.relu(self.conv6(x)))\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, x, device, len):\n",
    "        self.dl = x\n",
    "        self.device = device\n",
    "        self.len = len\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for item in self.dl: \n",
    "            yield to_device(item, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, x, y, transform):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "        self.len = len(x)\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, item):\n",
    "        #print(type(self.x[item]))\n",
    "        return self.transform(self.x[item]), torch.from_numpy(self.y[item])\n",
    "\n",
    "device = get_default_device()\n",
    "device\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "batch_size = 32\n",
    "\n",
    "print(xTrain.shape)\n",
    "print(yTrain.shape)\n",
    "\n",
    "\n",
    "myDataTrain = MyData(xTrain,yTrain, transform)\n",
    "myDataVal = MyData(xVal,yVal, transform)\n",
    "myDataTest = MyData(xTest,yTest, transform)\n",
    "\n",
    "dataTrain = torch.utils.data.DataLoader(myDataTrain, batch_size=batch_size)\n",
    "dataVal = torch.utils.data.DataLoader(myDataVal, batch_size=batch_size)\n",
    "dataTest = torch.utils.data.DataLoader(myDataTest, batch_size=batch_size)\n",
    "\n",
    "dataTrain = DeviceDataLoader(dataTrain, device,len(yTrain))\n",
    "dataVal = DeviceDataLoader(dataVal, device,len(yVal))\n",
    "dataTest = DeviceDataLoader(dataTest, device,len(yTest))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inception"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = to_device(InceptionNet(), device)\n",
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5\n",
    "\n",
    "history = fit(num_epochs, lr, model, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DenseNet\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = to_device(DenseNet(), device)\n",
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = to_device(ResNet(), device)\n",
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model3 = to_device(VGGNet(), device)\n",
    "evaluate(model3, dataTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model3, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate(model3, dataTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del(model3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "del(model)"
   ],
   "metadata": {
    "id": "GZFIl5PM0x6p",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet"
   ],
   "metadata": {
    "id": "M2mETVprfci0",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = to_device(ResNet(), device)\n",
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2aDc7re0fy_T",
    "outputId": "1f92003a-1d56-41c8-b969-e7d04f8c944b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 61,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 1.3815927505493164, 'val_acc': 0.23726190626621246}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3Ypuv45ghmS",
    "outputId": "e9b4a9ea-3e35-4176-8b50-b4dff162f3b8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 62,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.920762300491333, val_loss: 0.8073042035102844, val_acc: 0.9453125\n",
      "Epoch 2: train_loss: 0.7845194935798645, val_loss: 0.8051995635032654, val_acc: 0.9386160969734192\n",
      "Epoch 3: train_loss: 0.7670024037361145, val_loss: 0.7919043302536011, val_acc: 0.9542410969734192\n",
      "Epoch 4: train_loss: 0.7576763033866882, val_loss: 0.7860565781593323, val_acc: 0.9598214030265808\n",
      "Epoch 5: train_loss: 0.7519763708114624, val_loss: 0.7847854495048523, val_acc: 0.9553571343421936\n",
      "Epoch 6: train_loss: 0.7516723871231079, val_loss: 0.7830186486244202, val_acc: 0.9609375\n",
      "Epoch 7: train_loss: 0.7507798671722412, val_loss: 0.7796981334686279, val_acc: 0.9619792103767395\n",
      "Epoch 8: train_loss: 0.748507559299469, val_loss: 0.7801950573921204, val_acc: 0.9665178656578064\n",
      "Epoch 9: train_loss: 0.748406708240509, val_loss: 0.7927884459495544, val_acc: 0.9519345164299011\n",
      "Epoch 10: train_loss: 0.750078558921814, val_loss: 0.792548418045044, val_acc: 0.9508928656578064\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "evaluate(model, dataTest)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgzcsOAQY76a",
    "outputId": "52b4db95-2ca0-4940-9464-abb6fbc7407b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 63,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.7967091202735901, 'val_acc': 0.9445833563804626}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "del(model)"
   ],
   "metadata": {
    "id": "Tb8SgW3Q0ysS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# VGG\n"
   ],
   "metadata": {
    "id": "AJSiNYB7fZwX",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model3 = to_device(VGGNet(), device)\n",
    "evaluate(model3, dataTest)"
   ],
   "metadata": {
    "id": "23aoKetOeqii",
    "outputId": "74e96d94-2321-463a-b297-13ddaa513efe",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 58,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 1.3746545314788818, 'val_acc': 0.3095238208770752}"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs = 15\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model3, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "id": "-vYcwNOyfKlT",
    "outputId": "80a024ee-c976-4974-d4e5-f26792c94ec4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 59,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss: 0.9677273631095886, val_loss: 0.8717265725135803, val_acc: 0.8646577596664429\n",
      "Epoch 2: train_loss: 0.84929358959198, val_loss: 0.8476076722145081, val_acc: 0.8925595283508301\n",
      "Epoch 3: train_loss: 0.8223062753677368, val_loss: 0.8415981531143188, val_acc: 0.8982142806053162\n",
      "Epoch 4: train_loss: 0.8051403760910034, val_loss: 0.856124222278595, val_acc: 0.888244092464447\n",
      "Epoch 5: train_loss: 0.7976633906364441, val_loss: 0.8913146257400513, val_acc: 0.8511160612106323\n",
      "Epoch 6: train_loss: 0.7992236614227295, val_loss: 0.8433651328086853, val_acc: 0.896056592464447\n",
      "Epoch 7: train_loss: 0.7842244505882263, val_loss: 0.7988829016685486, val_acc: 0.9418154954910278\n",
      "Epoch 8: train_loss: 0.7712522745132446, val_loss: 0.8109492063522339, val_acc: 0.9317708611488342\n",
      "Epoch 9: train_loss: 0.7673804759979248, val_loss: 0.8073222041130066, val_acc: 0.9340029954910278\n",
      "Epoch 10: train_loss: 0.7665198445320129, val_loss: 0.8047615885734558, val_acc: 0.9407738447189331\n",
      "Epoch 11: train_loss: 0.7699206471443176, val_loss: 0.8085108399391174, val_acc: 0.9340773820877075\n",
      "Epoch 12: train_loss: 0.7734049558639526, val_loss: 0.826531171798706, val_acc: 0.9183779954910278\n",
      "Epoch 13: train_loss: 0.7839992046356201, val_loss: 0.8313900232315063, val_acc: 0.909375011920929\n",
      "Epoch 14: train_loss: 0.7744327187538147, val_loss: 0.8241991400718689, val_acc: 0.9160714149475098\n",
      "Epoch 15: train_loss: 0.7627151608467102, val_loss: 0.8333675861358643, val_acc: 0.9104910492897034\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "evaluate(model3, dataTest)"
   ],
   "metadata": {
    "id": "MoV-4KAYfYzv",
    "outputId": "e08bc181-449a-4c37-dced-e583160d55b4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 60,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.8236653208732605, 'val_acc': 0.917738139629364}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "del(model3)"
   ],
   "metadata": {
    "id": "vl3GJ8yy0zSp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MyLittleModel"
   ],
   "metadata": {
    "id": "X9e6HA05ff2D",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model2 = to_device(Net(), device)\n",
    "evaluate(model2, dataTest)"
   ],
   "metadata": {
    "id": "eGeVLq-0fOcs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1: train_loss: 1.5985661745071411, val_loss: 1.59907865524292, val_acc: 0.43465909361839294\n",
      "Epoch 2: train_loss: 1.5879095792770386, val_loss: 1.5929450988769531, val_acc: 0.4517045319080353\n",
      "Epoch 3: train_loss: 1.582120656967163, val_loss: 1.5874441862106323, val_acc: 0.4545454680919647\n",
      "Epoch 4: train_loss: 1.576361060142517, val_loss: 1.5819647312164307, val_acc: 0.4630681872367859\n",
      "Epoch 5: train_loss: 1.5712506771087646, val_loss: 1.5773649215698242, val_acc: 0.47159090638160706\n",
      "Epoch 6: train_loss: 1.5662802457809448, val_loss: 1.5726343393325806, val_acc: 0.47159090638160706\n",
      "Epoch 7: train_loss: 1.560564398765564, val_loss: 1.5653364658355713, val_acc: 0.4857954680919647\n",
      "Epoch 8: train_loss: 1.553512454032898, val_loss: 1.569851279258728, val_acc: 0.4943181872367859\n",
      "Epoch 9: train_loss: 1.546003818511963, val_loss: 1.5616538524627686, val_acc: 0.5056818127632141\n",
      "Epoch 10: train_loss: 1.5410611629486084, val_loss: 1.5586732625961304, val_acc: 0.5\n",
      "Epoch 11: train_loss: 1.5371712446212769, val_loss: 1.5553393363952637, val_acc: 0.5\n",
      "Epoch 12: train_loss: 1.5330556631088257, val_loss: 1.554300308227539, val_acc: 0.4943181872367859\n",
      "Epoch 13: train_loss: 1.5291756391525269, val_loss: 1.5538989305496216, val_acc: 0.4943181872367859\n",
      "Epoch 14: train_loss: 1.5256857872009277, val_loss: 1.551945447921753, val_acc: 0.5\n",
      "Epoch 15: train_loss: 1.5225411653518677, val_loss: 1.5473952293395996, val_acc: 0.5170454382896423\n",
      "Epoch 16: train_loss: 1.5202383995056152, val_loss: 1.5421479940414429, val_acc: 0.5142045617103577\n",
      "Epoch 17: train_loss: 1.5176920890808105, val_loss: 1.5363012552261353, val_acc: 0.5227272510528564\n",
      "Epoch 18: train_loss: 1.514556646347046, val_loss: 1.52908194065094, val_acc: 0.5369318127632141\n",
      "Epoch 19: train_loss: 1.512723445892334, val_loss: 1.5255613327026367, val_acc: 0.5454545617103577\n",
      "Epoch 20: train_loss: 1.5110138654708862, val_loss: 1.525581955909729, val_acc: 0.5340909361839294\n",
      "Epoch 21: train_loss: 1.5082021951675415, val_loss: 1.5250365734100342, val_acc: 0.5340909361839294\n",
      "Epoch 22: train_loss: 1.5094692707061768, val_loss: 1.525234580039978, val_acc: 0.53125\n",
      "Epoch 23: train_loss: 1.5095232725143433, val_loss: 1.5259275436401367, val_acc: 0.5340909361839294\n",
      "Epoch 24: train_loss: 1.5103774070739746, val_loss: 1.5282336473464966, val_acc: 0.5198863744735718\n",
      "Epoch 25: train_loss: 1.506618857383728, val_loss: 1.5264320373535156, val_acc: 0.5227272510528564\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 5.5e-5 \n",
    "\n",
    "history = fit(num_epochs, lr, model2, dataTrain, dataVal, opt_func)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cl91c3z2P1Gg",
    "outputId": "0a64519c-3c18-42e7-fc9b-a80bbb32ff5c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "evaluate(model2, dataTest)"
   ],
   "metadata": {
    "id": "ht3MrSkcRLh-",
    "outputId": "476fd114-baad-4e02-9c00-6fbfc1182cab",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:74: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'val_loss': 1.5115759372711182, 'val_acc': 0.524404764175415}"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 2, 2, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 0, 0, 3, 3, 2, 2, 4, 4,\n",
       "        0, 0, 1, 1, 2, 2, 3, 3, 2, 2, 1, 1, 1, 1, 2, 2, 0, 0, 5, 5, 3, 3, 2, 2,\n",
       "        3, 3, 4, 4, 4, 4, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 1, 1, 2, 2,\n",
       "        3, 3, 0, 0, 1, 1, 0, 0, 2, 2, 5, 5, 5, 5, 3, 3, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4, 0, 0, 5, 5, 4, 4, 4, 4, 2, 2, 3, 3,\n",
       "        1, 1, 1, 1, 3, 3, 3, 3], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "list(dataTest)[0][1].argmax(1)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYE7xXVuP1Gh",
    "outputId": "1ba0099b-a9f4-4eee-c35b-a5f66e35f845"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-35-5fca4af94384>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataTest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-25-2db3907a8b03>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1131\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 457\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    458\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m    453\u001B[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0;32m--> 454\u001B[0;31m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: conv2d() received an invalid combination of arguments - got (list, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!list!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "model(list(dataTest)[0][0]).argmax(1)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "j7HyN01hP1Gh",
    "outputId": "9a243cd8-1577-45cf-aa49-ac9d00333c90"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "W0YRtQfIx14k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "EI7eGhdeP1Gf"
   ]
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}